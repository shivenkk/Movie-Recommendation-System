{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cc75584e04a4c3a861ae4d32f9a9904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27e6f25cd1a94be89622576bec63a37d",
              "IPY_MODEL_c8012d4fca344b48b75e96cbff88df00",
              "IPY_MODEL_5856c9ffa58a4e3c95796b370d9d6bf0"
            ],
            "layout": "IPY_MODEL_8ed582d0747942838de602719208c1d7"
          }
        },
        "27e6f25cd1a94be89622576bec63a37d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_183e0db1ed5e40eaab6ea218c9e249b0",
            "placeholder": "​",
            "style": "IPY_MODEL_b27cfbeb418a4dcab9ab1cfcce5633d1",
            "value": "100%"
          }
        },
        "c8012d4fca344b48b75e96cbff88df00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ef8d144f004e4ab933869ddca8a8e0",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_300c42c827474a49beaf594c6b4690ae",
            "value": 128
          }
        },
        "5856c9ffa58a4e3c95796b370d9d6bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c49dc099ddb42c5b451574f6d9377c4",
            "placeholder": "​",
            "style": "IPY_MODEL_8250b5389f38460a869b96f0cc916d2e",
            "value": " 128/128 [1:36:47&lt;00:00, 44.89s/it]"
          }
        },
        "8ed582d0747942838de602719208c1d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "183e0db1ed5e40eaab6ea218c9e249b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b27cfbeb418a4dcab9ab1cfcce5633d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32ef8d144f004e4ab933869ddca8a8e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300c42c827474a49beaf594c6b4690ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c49dc099ddb42c5b451574f6d9377c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8250b5389f38460a869b96f0cc916d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import the dataset\n",
        "import pandas as pd\n",
        "movies_df = pd.read_csv('movies.csv')\n",
        "ratings_df = pd.read_csv('ratings.csv')"
      ],
      "metadata": {
        "id": "rD7V-1QK3pLX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The dimensions of movies dataframe are:', movies_df.shape)\n",
        "print('\\nThe dimensions of ratings dataframe are:', ratings_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp0yv2kK3_3l",
        "outputId": "5c538168-fc59-434c-b745-5be8b11a17ab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dimensions of movies dataframe are: (62423, 3)\n",
            "\n",
            "The dimensions of ratings dataframe are: (2721202, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping movie IDs to movie names\n",
        "movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
        "\n",
        "# Counting the number of unique users and movies\n",
        "n_users = len(ratings_df.userId.unique())\n",
        "n_items = len(ratings_df.movieId.unique())\n",
        "\n",
        "# Displaying the counts\n",
        "print(\"Number of unique users:\", n_users)\n",
        "print(\"Number of unique movies:\", n_items)\n",
        "print(\"The full rating matrix will have:\", n_users * n_items, 'elements.')\n",
        "\n",
        "# Computing the sparsity of the rating matrix\n",
        "print(\"Number of ratings:\", len(ratings_df))\n",
        "sparsity_percentage = len(ratings_df) / (n_users * n_items) * 100\n",
        "print(\"Therefore: \", sparsity_percentage, '% of the matrix is filled.')\n",
        "print(\"We have an incredibly sparse matrix to work with here.\")\n",
        "print(\"As the number of users and products grow, the matrix elements will increase exponentially.\")\n",
        "print(\"Storing a full matrix in memory at a global scale would be a challenge.\")\n",
        "\n",
        "# Highlighting the advantage of matrix factorization\n",
        "print(\"One advantage here is that matrix factorization can implicitly represent the rating matrix, mitigating the need for all data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kL4kGzd4N52",
        "outputId": "05dec33c-94df-4c87-85e8-31d1a4629e32"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique users: 18075\n",
            "Number of unique movies: 30663\n",
            "The full rating matrix will have: 554233725 elements.\n",
            "Number of ratings: 2721202\n",
            "Therefore:  0.49098455710178945 % of the matrix is filled.\n",
            "We have an incredibly sparse matrix to work with here.\n",
            "As the number of users and products grow, the matrix elements will increase exponentially.\n",
            "Storing a full matrix in memory at a global scale would be a challenge.\n",
            "One advantage here is that matrix factorization can implicitly represent the rating matrix, mitigating the need for all data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "class MatrixFactorization(torch.nn.Module):\n",
        "    def __init__(self, n_users, n_items, n_factors=20):\n",
        "        super().__init__()\n",
        "        # Define user and item embeddings\n",
        "        self.user_factors = torch.nn.Embedding(n_users, n_factors)  # User embedding lookup table\n",
        "        self.item_factors = torch.nn.Embedding(n_items, n_factors)  # Item embedding lookup table\n",
        "        # Initialize embeddings with uniform distribution\n",
        "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
        "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # Perform matrix multiplication\n",
        "        users, items = data[:, 0], data[:, 1]\n",
        "        return (self.user_factors(users) * self.item_factors(items)).sum(1)\n",
        "\n",
        "    def predict(self, user, item):\n",
        "        # Predict rating for user-item pair\n",
        "        return self.forward(torch.LongTensor([user]), torch.LongTensor([item])).item()\n"
      ],
      "metadata": {
        "id": "0-GeiL884XLS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class Loader(Dataset):\n",
        "    def __init__(self):\n",
        "        self.ratings = ratings_df.copy()\n",
        "\n",
        "        # Extract unique user and movie IDs\n",
        "        users = ratings_df.userId.unique()\n",
        "        movies = ratings_df.movieId.unique()\n",
        "\n",
        "        # Map original IDs to continuous indices for users and movies\n",
        "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
        "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
        "\n",
        "        # Map continuous indices back to original IDs for users and movies\n",
        "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
        "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
        "\n",
        "        # Replace original IDs with continuous indices\n",
        "        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n",
        "        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n",
        "\n",
        "        # Prepare input features and target ratings as tensors\n",
        "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
        "        self.y = self.ratings['rating'].values\n",
        "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.x[index], self.y[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)"
      ],
      "metadata": {
        "id": "o-FWrKXc4ZXy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 128\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "print(\"Is running on GPU:\", cuda)\n",
        "\n",
        "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
        "print(model)\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)\n",
        "# GPU enable if you have a GPU...\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "# MSE loss\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# ADAM optimizier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Train data\n",
        "train_set = Loader()\n",
        "train_loader = DataLoader(train_set, 128, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V8JZp5O4d74",
        "outputId": "f15628d2-342e-44de-c475-0d0abddb0ac9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is running on GPU: True\n",
            "MatrixFactorization(\n",
            "  (user_factors): Embedding(18075, 8)\n",
            "  (item_factors): Embedding(30663, 8)\n",
            ")\n",
            "user_factors.weight tensor([[0.0487, 0.0007, 0.0353,  ..., 0.0188, 0.0205, 0.0047],\n",
            "        [0.0366, 0.0388, 0.0212,  ..., 0.0157, 0.0060, 0.0118],\n",
            "        [0.0295, 0.0235, 0.0399,  ..., 0.0394, 0.0193, 0.0289],\n",
            "        ...,\n",
            "        [0.0024, 0.0256, 0.0193,  ..., 0.0357, 0.0129, 0.0151],\n",
            "        [0.0114, 0.0156, 0.0399,  ..., 0.0174, 0.0380, 0.0179],\n",
            "        [0.0459, 0.0192, 0.0139,  ..., 0.0232, 0.0096, 0.0270]])\n",
            "item_factors.weight tensor([[0.0328, 0.0331, 0.0295,  ..., 0.0388, 0.0496, 0.0272],\n",
            "        [0.0247, 0.0373, 0.0181,  ..., 0.0036, 0.0322, 0.0260],\n",
            "        [0.0174, 0.0071, 0.0104,  ..., 0.0174, 0.0241, 0.0266],\n",
            "        ...,\n",
            "        [0.0125, 0.0188, 0.0281,  ..., 0.0259, 0.0002, 0.0097],\n",
            "        [0.0048, 0.0430, 0.0223,  ..., 0.0498, 0.0157, 0.0479],\n",
            "        [0.0081, 0.0275, 0.0321,  ..., 0.0496, 0.0291, 0.0370]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for it in tqdm(range(num_epochs)):\n",
        "    losses = []\n",
        "    for x, y in train_loader:\n",
        "         if cuda:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
        "            losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0cc75584e04a4c3a861ae4d32f9a9904",
            "27e6f25cd1a94be89622576bec63a37d",
            "c8012d4fca344b48b75e96cbff88df00",
            "5856c9ffa58a4e3c95796b370d9d6bf0",
            "8ed582d0747942838de602719208c1d7",
            "183e0db1ed5e40eaab6ea218c9e249b0",
            "b27cfbeb418a4dcab9ab1cfcce5633d1",
            "32ef8d144f004e4ab933869ddca8a8e0",
            "300c42c827474a49beaf594c6b4690ae",
            "0c49dc099ddb42c5b451574f6d9377c4",
            "8250b5389f38460a869b96f0cc916d2e"
          ]
        },
        "id": "PUQaQ9m344Hn",
        "outputId": "042a455a-b043-4f30-b383-27ce0ec737ce"
      },
      "execution_count": 29,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-dad152416852>:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for it in tqdm(range(num_epochs)):\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cc75584e04a4c3a861ae4d32f9a9904",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/128 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter #0 Loss: 2.803487405506149\n",
            "iter #1 Loss: 0.9263335081393833\n",
            "iter #2 Loss: 0.8551078334927334\n",
            "iter #3 Loss: 0.8264788632152335\n",
            "iter #4 Loss: 0.8061802979330913\n",
            "iter #5 Loss: 0.7766145468332918\n",
            "iter #6 Loss: 0.744028598827118\n",
            "iter #7 Loss: 0.7160166225661563\n",
            "iter #8 Loss: 0.6883949904806863\n",
            "iter #9 Loss: 0.6637531934654723\n",
            "iter #10 Loss: 0.6440824070870035\n",
            "iter #11 Loss: 0.6291176713112941\n",
            "iter #12 Loss: 0.6176762880675095\n",
            "iter #13 Loss: 0.6087525220281206\n",
            "iter #14 Loss: 0.6017873790672335\n",
            "iter #15 Loss: 0.5963226177478218\n",
            "iter #16 Loss: 0.5919963951996219\n",
            "iter #17 Loss: 0.5885604104004373\n",
            "iter #18 Loss: 0.5857339702399407\n",
            "iter #19 Loss: 0.5833248411442801\n",
            "iter #20 Loss: 0.581538952633332\n",
            "iter #21 Loss: 0.5798245703372211\n",
            "iter #22 Loss: 0.5783745696451007\n",
            "iter #23 Loss: 0.5772500965873923\n",
            "iter #24 Loss: 0.5761000486302802\n",
            "iter #25 Loss: 0.5751755471147688\n",
            "iter #26 Loss: 0.5743872997397426\n",
            "iter #27 Loss: 0.5734549330395006\n",
            "iter #28 Loss: 0.5729341201701482\n",
            "iter #29 Loss: 0.5723041168567379\n",
            "iter #30 Loss: 0.5716372874738019\n",
            "iter #31 Loss: 0.571198345600213\n",
            "iter #32 Loss: 0.5708898809168099\n",
            "iter #33 Loss: 0.5704513869485761\n",
            "iter #34 Loss: 0.5700782150520767\n",
            "iter #35 Loss: 0.5696584051550275\n",
            "iter #36 Loss: 0.5694870854310011\n",
            "iter #37 Loss: 0.5692398928449273\n",
            "iter #38 Loss: 0.5687581935457654\n",
            "iter #39 Loss: 0.5687187293903624\n",
            "iter #40 Loss: 0.5684609427823846\n",
            "iter #41 Loss: 0.5682059294627393\n",
            "iter #42 Loss: 0.5679603511378211\n",
            "iter #43 Loss: 0.5678157076183514\n",
            "iter #44 Loss: 0.5676867416428152\n",
            "iter #45 Loss: 0.567449150985126\n",
            "iter #46 Loss: 0.5673792105458978\n",
            "iter #47 Loss: 0.5671455242756057\n",
            "iter #48 Loss: 0.5671063273514315\n",
            "iter #49 Loss: 0.5669843108274975\n",
            "iter #50 Loss: 0.5668938286160929\n",
            "iter #51 Loss: 0.566888903124873\n",
            "iter #52 Loss: 0.5665824120477024\n",
            "iter #53 Loss: 0.5667139858203684\n",
            "iter #54 Loss: 0.5664894126180423\n",
            "iter #55 Loss: 0.5664059111016153\n",
            "iter #56 Loss: 0.566345226118448\n",
            "iter #57 Loss: 0.5662851322529906\n",
            "iter #58 Loss: 0.5663320297440155\n",
            "iter #59 Loss: 0.5663275821216804\n",
            "iter #60 Loss: 0.5661821352417807\n",
            "iter #61 Loss: 0.566131234292365\n",
            "iter #62 Loss: 0.5662392044813142\n",
            "iter #63 Loss: 0.5662090212905733\n",
            "iter #64 Loss: 0.5661486176772154\n",
            "iter #65 Loss: 0.5660524861300092\n",
            "iter #66 Loss: 0.5661680546986081\n",
            "iter #67 Loss: 0.5660071835720865\n",
            "iter #68 Loss: 0.5660215711499708\n",
            "iter #69 Loss: 0.5660543096424383\n",
            "iter #70 Loss: 0.565880877229535\n",
            "iter #71 Loss: 0.5659759186271329\n",
            "iter #72 Loss: 0.565956151876546\n",
            "iter #73 Loss: 0.566032053652173\n",
            "iter #74 Loss: 0.5660296583178462\n",
            "iter #75 Loss: 0.5659548997164109\n",
            "iter #76 Loss: 0.5660645142071447\n",
            "iter #77 Loss: 0.5661693792772652\n",
            "iter #78 Loss: 0.5659215340245365\n",
            "iter #79 Loss: 0.5659842209065173\n",
            "iter #80 Loss: 0.5660714353072901\n",
            "iter #81 Loss: 0.5661010840930473\n",
            "iter #82 Loss: 0.5660413767564219\n",
            "iter #83 Loss: 0.5660155223782402\n",
            "iter #84 Loss: 0.5661251676595671\n",
            "iter #85 Loss: 0.5660882337143257\n",
            "iter #86 Loss: 0.5661352294219459\n",
            "iter #87 Loss: 0.5663434447301858\n",
            "iter #88 Loss: 0.5662407727493279\n",
            "iter #89 Loss: 0.5661886543413994\n",
            "iter #90 Loss: 0.5662822089325339\n",
            "iter #91 Loss: 0.5662282141291748\n",
            "iter #92 Loss: 0.5661383945021782\n",
            "iter #93 Loss: 0.5663541214654497\n",
            "iter #94 Loss: 0.5663606028481687\n",
            "iter #95 Loss: 0.5663884801844438\n",
            "iter #96 Loss: 0.5663523203103698\n",
            "iter #97 Loss: 0.5664063713021807\n",
            "iter #98 Loss: 0.5663760908025116\n",
            "iter #99 Loss: 0.5665506830654499\n",
            "iter #100 Loss: 0.5664958553054035\n",
            "iter #101 Loss: 0.5664879226757464\n",
            "iter #102 Loss: 0.5666149962430614\n",
            "iter #103 Loss: 0.566502925969471\n",
            "iter #104 Loss: 0.5665730879173342\n",
            "iter #105 Loss: 0.5667379673538854\n",
            "iter #106 Loss: 0.5666764534596329\n",
            "iter #107 Loss: 0.566797073397116\n",
            "iter #108 Loss: 0.5667732941352973\n",
            "iter #109 Loss: 0.566793060845232\n",
            "iter #110 Loss: 0.5668121556824148\n",
            "iter #111 Loss: 0.5669612755401451\n",
            "iter #112 Loss: 0.5669163783050212\n",
            "iter #113 Loss: 0.5669771496448333\n",
            "iter #114 Loss: 0.5671508125575331\n",
            "iter #115 Loss: 0.5668939072221714\n",
            "iter #116 Loss: 0.5670767422467611\n",
            "iter #117 Loss: 0.5670283858283218\n",
            "iter #118 Loss: 0.5670806078925407\n",
            "iter #119 Loss: 0.5673583178520764\n",
            "iter #120 Loss: 0.5671086820222697\n",
            "iter #121 Loss: 0.567307842292263\n",
            "iter #122 Loss: 0.5671184123375453\n",
            "iter #123 Loss: 0.567159589201296\n",
            "iter #124 Loss: 0.5672293470795717\n",
            "iter #125 Loss: 0.567233370649624\n",
            "iter #126 Loss: 0.5674774038783246\n",
            "iter #127 Loss: 0.5673786313252862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By training the model, latent factors for movies and users have been tuned.\n",
        "user_factors = None\n",
        "item_factors = None\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)\n",
        "        if user_factors is None:\n",
        "            user_factors = param.data\n",
        "        else:\n",
        "            item_factors = param.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEHvpCVF44zn",
        "outputId": "e8b32094-b27f-471a-af81-6f7a39e20ae3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_factors.weight tensor([[ 0.0509,  0.0361,  0.5975,  ...,  1.8296,  1.0490,  3.5387],\n",
            "        [ 1.1142,  1.8561, -1.0454,  ...,  1.1626,  3.3761,  2.5774],\n",
            "        [ 1.6750,  1.3596,  0.8403,  ...,  2.2892,  2.6331,  2.6432],\n",
            "        ...,\n",
            "        [ 1.7657,  1.6105,  0.0097,  ...,  2.4129,  1.2036,  3.9554],\n",
            "        [ 1.4458,  2.1596, -0.0466,  ...,  1.1596,  3.3012,  0.9978],\n",
            "        [ 2.4562,  2.4345, -1.1092,  ...,  2.4210,  2.1933,  2.2407]],\n",
            "       device='cuda:0')\n",
            "item_factors.weight tensor([[ 0.2802, -0.3090, -0.0220,  ...,  0.5183,  0.2685,  0.6917],\n",
            "        [ 0.1544, -0.0132,  0.6099,  ...,  0.2218,  0.4675,  0.4947],\n",
            "        [ 0.0267, -0.0661,  0.6312,  ...,  0.1447,  0.4745,  0.4848],\n",
            "        ...,\n",
            "        [ 0.2413,  0.2478,  0.2567,  ...,  0.2547,  0.2291,  0.2387],\n",
            "        [ 0.2967,  0.3355,  0.3150,  ...,  0.3421,  0.3078,  0.3401],\n",
            "        [ 0.0628,  0.0821,  0.0868,  ...,  0.1041,  0.0837,  0.0915]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()"
      ],
      "metadata": {
        "id": "QD7_NQLt49jm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trained_movie_embeddings) # unique movie factor weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Oof0Fq4-8X",
        "outputId": "c40e4965-05e2-439b-cfaa-8b7271c6d37b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30663"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "# Fit the clusters based on the movie weights\n",
        "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOYPmBBZ5AFM",
        "outputId": "345560d0-2a62-48cb-c60c-a0e200e0777b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this observation, it's apparent that movies within the same cluster exhibit similar genres. It's noteworthy that the algorithm operates without awareness of movie titles, deriving relationships solely from numerical representations of user responses to movie selections."
      ],
      "metadata": {
        "id": "0QVyRjrl5C-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cluster in range(10):\n",
        "  print(\"Cluster #{}\".format(cluster))\n",
        "  movs = []\n",
        "  for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
        "    movid = train_set.idx2movieid[movidx]\n",
        "    rat_count = ratings_df.loc[ratings_df['movieId']==movid].count()[0]\n",
        "    movs.append((movie_names[movid], rat_count))\n",
        "  for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
        "    print(\"\\t\", mov[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlx5y6kW5BQJ",
        "outputId": "a3a07931-04e7-43ea-adea-5cf9f3e52a4b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster #0\n",
            "\t Broken Arrow (1996)\n",
            "\t X2: X-Men United (2003)\n",
            "\t Mummy, The (1999)\n",
            "\t Nutty Professor, The (1996)\n",
            "\t Mission: Impossible II (2000)\n",
            "\t Charlie's Angels (2000)\n",
            "\t Avengers, The (2012)\n",
            "\t I, Robot (2004)\n",
            "\t Starship Troopers (1997)\n",
            "\t Judge Dredd (1995)\n",
            "Cluster #1\n",
            "\t Birdcage, The (1996)\n",
            "\t Sense and Sensibility (1995)\n",
            "\t Little Miss Sunshine (2006)\n",
            "\t Juno (2007)\n",
            "\t Big Fish (2003)\n",
            "\t What's Eating Gilbert Grape (1993)\n",
            "\t Dogma (1999)\n",
            "\t The Butterfly Effect (2004)\n",
            "\t English Patient, The (1996)\n",
            "\t 10 Things I Hate About You (1999)\n",
            "Cluster #2\n",
            "\t Pulp Fiction (1994)\n",
            "\t Reservoir Dogs (1992)\n",
            "\t Kill Bill: Vol. 1 (2003)\n",
            "\t Kill Bill: Vol. 2 (2004)\n",
            "\t Trainspotting (1996)\n",
            "\t Donnie Darko (2001)\n",
            "\t Inglourious Basterds (2009)\n",
            "\t Requiem for a Dream (2000)\n",
            "\t Sin City (2005)\n",
            "\t Lost in Translation (2003)\n",
            "Cluster #3\n",
            "\t RoboCop (1987)\n",
            "\t Searchers, The (1956)\n",
            "\t Re-Animator (1985)\n",
            "\t Godzilla (Gojira) (1954)\n",
            "\t Manhunter (1986)\n",
            "\t Dead Ringers (1988)\n",
            "\t Tree of Life, The (2011)\n",
            "\t Mummy, The (1932)\n",
            "\t Runaway Train (1985)\n",
            "\t Rio Bravo (1959)\n",
            "Cluster #4\n",
            "\t Lion King, The (1994)\n",
            "\t Home Alone (1990)\n",
            "\t Jumanji (1995)\n",
            "\t Back to the Future Part II (1989)\n",
            "\t Back to the Future Part III (1990)\n",
            "\t Ace Ventura: When Nature Calls (1995)\n",
            "\t Addams Family Values (1993)\n",
            "\t Grease (1978)\n",
            "\t Honey, I Shrunk the Kids (1989)\n",
            "\t Santa Clause, The (1994)\n",
            "Cluster #5\n",
            "\t Silence of the Lambs, The (1991)\n",
            "\t Star Wars: Episode IV - A New Hope (1977)\n",
            "\t Jurassic Park (1993)\n",
            "\t Braveheart (1995)\n",
            "\t Terminator 2: Judgment Day (1991)\n",
            "\t Star Wars: Episode V - The Empire Strikes Back (1980)\n",
            "\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
            "\t Godfather, The (1972)\n",
            "\t Fugitive, The (1993)\n",
            "\t Apollo 13 (1995)\n",
            "Cluster #6\n",
            "\t Tank Girl (1995)\n",
            "\t Imaginarium of Doctor Parnassus, The (2009)\n",
            "\t But I'm a Cheerleader (1999)\n",
            "\t Joe's Apartment (1996)\n",
            "\t Attack of the Killer Tomatoes! (1978)\n",
            "\t Velvet Goldmine (1998)\n",
            "\t Pillow Book, The (1996)\n",
            "\t Butcher Boy, The (1997)\n",
            "\t Man Who Fell to Earth, The (1976)\n",
            "\t Until the End of the World (Bis ans Ende der Welt) (1991)\n",
            "Cluster #7\n",
            "\t Hangover Part II, The (2011)\n",
            "\t Twilight Saga: Breaking Dawn - Part 1, The (2011)\n",
            "\t Twilight Saga: Breaking Dawn - Part 2, The (2012)\n",
            "\t Dumb and Dumber To (2014)\n",
            "\t Alvin and the Chipmunks (2007)\n",
            "\t Good Year, A (2006)\n",
            "\t Bad Company (2002)\n",
            "\t Casino Royale (1967)\n",
            "\t Deuce Bigalow: European Gigolo (2005)\n",
            "\t National Security (2003)\n",
            "Cluster #8\n",
            "\t Forrest Gump (1994)\n",
            "\t Shawshank Redemption, The (1994)\n",
            "\t Matrix, The (1999)\n",
            "\t Schindler's List (1993)\n",
            "\t Fight Club (1999)\n",
            "\t Toy Story (1995)\n",
            "\t Usual Suspects, The (1995)\n",
            "\t Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
            "\t Star Wars: Episode VI - Return of the Jedi (1983)\n",
            "\t American Beauty (1999)\n",
            "Cluster #9\n",
            "\t Fargo (1996)\n",
            "\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
            "\t Monty Python and the Holy Grail (1975)\n",
            "\t Alien (1979)\n",
            "\t Blade Runner (1982)\n",
            "\t One Flew Over the Cuckoo's Nest (1975)\n",
            "\t Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
            "\t Eternal Sunshine of the Spotless Mind (2004)\n",
            "\t Aliens (1986)\n",
            "\t Babe (1995)\n"
          ]
        }
      ]
    }
  ]
}